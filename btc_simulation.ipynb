{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BTC Fake - Training Completion Simulator\n",
    "\n",
    "This notebook simulates employees completing training courses from both manager assignments and AI recommendations.\n",
    "\n",
    "## How it works:\n",
    "1. **Preprocessing**: Downloads training content files from SFTP server\n",
    "2. **Manager Assigns Training**: Selects and assigns up to 3 Daily Dose contents to all employees\n",
    "3. **Employee Completes Training**: \n",
    "   - Loads manager assignments and AI recommendations for each employee\n",
    "   - Completes training based on employee type (A, B, or F)\n",
    "4. **Output Generation**:\n",
    "   - NonCompletedAssignments CSV file (manager assignments)\n",
    "   - ContentUserCompletion CSV file (completed training with source tracking)\n",
    "5. **Summary**: Prints completion details showing which training came from manager vs AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python executable: /Users/khansen/craft/stores/python/python-projects-rdi/btc_fake/.venv/bin/python\n",
      "Python version: 3.13.2 (main, Feb  4 2025, 14:51:09) [Clang 16.0.0 (clang-1600.0.26.6)]\n",
      "Success!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(\"Python executable:\", sys.executable)\n",
    "print(\"Python version:\", sys.version)\n",
    "from dotenv import load_dotenv\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import pandas as pd\nimport requests\nfrom datetime import datetime, timedelta\nimport random\nimport string\nfrom typing import List, Dict\nimport urllib3\nimport pytz\n\n# Disable SSL warnings when ignoring certificate verification\nurllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n\n# Define Pacific timezone globally for all timestamp operations\n# This ensures all timestamps in output files use PT timezone, not UTC\nPT = pytz.timezone('America/Los_Angeles')\n\n# Configuration\nAPI_BASE_URL = \"https://dataiku-api-devqa.lower.internal.sephora.com\"\nAPI_ENDPOINT = \"/public/api/v1/mltr/v3/run\"\nEMPLOYEES_FILE = \"input/employees.csv\"\nOUTPUT_DIR = \"generated_files\"\nSFTP_LOCAL_DIR = \"downloaded_files\""
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing - Download Files from SFTP\n",
    "\n",
    "This section prepares for a fresh simulation run:\n",
    "\n",
    "## Cleanup\n",
    "1. Removes all files from `downloaded_files/` directory\n",
    "2. Removes all files from `generated_files/` directory\n",
    "3. Ensures each run starts with a clean slate\n",
    "\n",
    "## Generate UserCompletion File\n",
    "1. Copies the UserCompletion template from `docs/sample_files/`\n",
    "2. Renames it with the current date (YYYY_m_d format)\n",
    "3. Places it in `generated_files/` directory\n",
    "\n",
    "## Download Files from SFTP Server\n",
    "1. **CourseCatalog** - Training curriculum elements like Courses and components\n",
    "2. **StandAloneContent** - All training content (videos, PDFs, documents)\n",
    "\n",
    "## Requirements:\n",
    "1. Copy `.env.example` to `.env` and add your SFTP password\n",
    "2. Files will be downloaded to `downloaded_files/` directory\n",
    "3. The system finds the most recent file based on the date in the filename\n",
    "\n",
    "## File Formats:\n",
    "- CourseCatalog: `CourseCatalog_V2_YYYY_M_DD_1_random.csv`\n",
    "- StandAloneContent: `StandAloneContent_v2_YYYY_M_DD_1_random.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "PREPROCESSING - Cleanup\n",
      "================================================================================\n",
      "\n",
      "Cleaning up directories from previous runs...\n",
      "\n",
      "Cleaning generated_files/...\n",
      "  Removed 3 file(s)\n",
      "\n",
      "Cleaning downloaded_files/...\n",
      "  Removed 2 file(s)\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cleanup: Remove old files from previous runs\n",
    "import os\n",
    "import glob\n",
    "\n",
    "def cleanup_directory(directory: str) -> int:\n",
    "    \"\"\"\n",
    "    Remove all files in a directory (keeps the directory itself and .gitkeep files).\n",
    "    \n",
    "    Args:\n",
    "        directory: Path to directory to clean\n",
    "    \n",
    "    Returns:\n",
    "        Number of files removed\n",
    "    \"\"\"\n",
    "    if not os.path.exists(directory):\n",
    "        print(f\"  Directory does not exist: {directory}\")\n",
    "        return 0\n",
    "    \n",
    "    files_removed = 0\n",
    "    pattern = os.path.join(directory, \"*\")\n",
    "    \n",
    "    for file_path in glob.glob(pattern):\n",
    "        # Skip .gitkeep files\n",
    "        if os.path.basename(file_path) == \".gitkeep\":\n",
    "            continue\n",
    "        \n",
    "        # Only remove files, not subdirectories\n",
    "        if os.path.isfile(file_path):\n",
    "            try:\n",
    "                os.remove(file_path)\n",
    "                files_removed += 1\n",
    "            except Exception as e:\n",
    "                print(f\"  Error removing {file_path}: {e}\")\n",
    "    \n",
    "    return files_removed\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"PREPROCESSING - Cleanup\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "print(\"Cleaning up directories from previous runs...\")\n",
    "print()\n",
    "\n",
    "# Clean generated_files directory\n",
    "print(f\"Cleaning {OUTPUT_DIR}/...\")\n",
    "removed = cleanup_directory(OUTPUT_DIR)\n",
    "print(f\"  Removed {removed} file(s)\")\n",
    "print()\n",
    "\n",
    "# Clean downloaded_files directory\n",
    "print(f\"Cleaning {SFTP_LOCAL_DIR}/...\")\n",
    "removed = cleanup_directory(SFTP_LOCAL_DIR)\n",
    "print(f\"  Removed {removed} file(s)\")\n",
    "print()\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Generate UserCompletion file from template\nimport shutil\n\ndef generate_user_completion_file() -> str:\n    \"\"\"\n    Copy the UserCompletion template file to generated_files with current date in PT.\n    \n    Returns:\n        Path to the generated file, or None if generation fails\n    \"\"\"\n    # Source template file\n    source_file = \"docs/sample_files/UserCompletion_v2_YYYY_m_d_1_000001.csv\"\n    \n    if not os.path.exists(source_file):\n        print(f\"  Template file not found: {source_file}\")\n        return None\n    \n    # Generate new filename with current date in PT\n    now = datetime.now(PT)\n    year = now.strftime(\"%Y\")\n    month = now.strftime(\"%-m\")  # No leading zero\n    day = now.strftime(\"%-d\")    # No leading zero\n    \n    new_filename = f\"UserCompletion_v2_{year}_{month}_{day}_1_000001.csv\"\n    destination_file = os.path.join(OUTPUT_DIR, new_filename)\n    \n    # Copy the file\n    try:\n        shutil.copy2(source_file, destination_file)\n        return destination_file\n    except Exception as e:\n        print(f\"  Error copying file: {e}\")\n        return None\n\nprint(\"=\" * 80)\nprint(\"PREPROCESSING - Generate UserCompletion File\")\nprint(\"=\" * 80)\nprint()\n\nprint(\"Generating UserCompletion file from template...\")\nuser_completion_path = generate_user_completion_file()\n\nif user_completion_path:\n    print(f\"✓ UserCompletion file generated successfully\")\n    print(f\"  File: {user_completion_path}\")\nelse:\n    print(\"✗ Failed to generate UserCompletion file\")\n\nprint()\nprint(\"=\" * 80)\nprint()"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import SFTP libraries and load environment\n",
    "import os\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "import paramiko\n",
    "from datetime import datetime\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# SFTP Configuration\n",
    "SFTP_HOST = \"sftp.sephora.com\"\n",
    "SFTP_USER = \"SephoraMSL\"\n",
    "SFTP_PASSWORD = os.getenv(\"SFTP_PASSWORD\", \"your_sftp_password_placeholder\")\n",
    "SFTP_REMOTE_PATH = \"/inbound/BTC/retailData/prod/vendor/mySephoraLearning-archive\"\n",
    "\n",
    "def parse_course_catalog_filename(filename: str) -> tuple:\n",
    "    \"\"\"\n",
    "    Parse course catalog filename to extract date components.\n",
    "    Format: CourseCatalog_V2_YYYY_M_DD_1_random.csv\n",
    "    \n",
    "    Args:\n",
    "        filename: The course catalog filename\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (year, month, day, datetime_obj) or None if parsing fails\n",
    "    \"\"\"\n",
    "    pattern = r'CourseCatalog_V2_(\\d{4})_(\\d{1,2})_(\\d{1,2})_\\d+_[a-z0-9]+\\.csv'\n",
    "    match = re.match(pattern, filename, re.IGNORECASE)\n",
    "    \n",
    "    if match:\n",
    "        year = int(match.group(1))\n",
    "        month = int(match.group(2))\n",
    "        day = int(match.group(3))\n",
    "        \n",
    "        try:\n",
    "            date_obj = datetime(year, month, day)\n",
    "            return (year, month, day, date_obj)\n",
    "        except ValueError:\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "def parse_standalone_content_filename(filename: str) -> tuple:\n",
    "    \"\"\"\n",
    "    Parse standalone content filename to extract date components.\n",
    "    Format: StandAloneContent_v2_YYYY_M_DD_1_random.csv\n",
    "    \n",
    "    Args:\n",
    "        filename: The standalone content filename\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (year, month, day, datetime_obj) or None if parsing fails\n",
    "    \"\"\"\n",
    "    pattern = r'StandAloneContent_v2_(\\d{4})_(\\d{1,2})_(\\d{1,2})_\\d+_[a-z0-9]+\\.csv'\n",
    "    match = re.match(pattern, filename, re.IGNORECASE)\n",
    "    \n",
    "    if match:\n",
    "        year = int(match.group(1))\n",
    "        month = int(match.group(2))\n",
    "        day = int(match.group(3))\n",
    "        \n",
    "        try:\n",
    "            date_obj = datetime(year, month, day)\n",
    "            return (year, month, day, date_obj)\n",
    "        except ValueError:\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "def download_most_recent_course_catalog() -> str:\n",
    "    \"\"\"\n",
    "    Connect to SFTP server and download the most recent CourseCatalog file.\n",
    "    \n",
    "    Returns:\n",
    "        Path to the downloaded file, or None if download fails\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create SFTP connection\n",
    "        transport = paramiko.Transport((SFTP_HOST, 22))\n",
    "        transport.connect(username=SFTP_USER, password=SFTP_PASSWORD)\n",
    "        sftp = paramiko.SFTPClient.from_transport(transport)\n",
    "        \n",
    "        print(f\"Connected to SFTP server: {SFTP_HOST}\")\n",
    "        \n",
    "        # Change to remote directory\n",
    "        sftp.chdir(SFTP_REMOTE_PATH)\n",
    "        print(f\"Changed to directory: {SFTP_REMOTE_PATH}\")\n",
    "        \n",
    "        # List all files in the directory\n",
    "        files = sftp.listdir()\n",
    "        print(f\"Found {len(files)} files in directory\")\n",
    "        \n",
    "        # Filter for course catalog files and parse dates\n",
    "        catalog_files = []\n",
    "        for filename in files:\n",
    "            parsed = parse_course_catalog_filename(filename)\n",
    "            if parsed:\n",
    "                catalog_files.append((filename, parsed[3]))  # (filename, datetime_obj)\n",
    "        \n",
    "        if not catalog_files:\n",
    "            print(\"No valid CourseCatalog files found\")\n",
    "            sftp.close()\n",
    "            transport.close()\n",
    "            return None\n",
    "        \n",
    "        # Sort by date (most recent first)\n",
    "        catalog_files.sort(key=lambda x: x[1], reverse=True)\n",
    "        most_recent_file = catalog_files[0][0]\n",
    "        most_recent_date = catalog_files[0][1]\n",
    "        \n",
    "        print(f\"Most recent file: {most_recent_file} (date: {most_recent_date.strftime('%Y-%m-%d')})\")\n",
    "        \n",
    "        # Download the file\n",
    "        local_path = os.path.join(SFTP_LOCAL_DIR, most_recent_file)\n",
    "        sftp.get(most_recent_file, local_path)\n",
    "        print(f\"Downloaded to: {local_path}\")\n",
    "        \n",
    "        # Close connections\n",
    "        sftp.close()\n",
    "        transport.close()\n",
    "        \n",
    "        return local_path\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading course catalog: {e}\")\n",
    "        print(f\"  SFTP Host: {SFTP_HOST}\")\n",
    "        print(f\"  SFTP Path: {SFTP_REMOTE_PATH}\")\n",
    "        print(f\"  SFTP User: {SFTP_USER}\")\n",
    "        return None\n",
    "\n",
    "def download_most_recent_standalone_content() -> str:\n",
    "    \"\"\"\n",
    "    Connect to SFTP server and download the most recent StandAloneContent file.\n",
    "    \n",
    "    Returns:\n",
    "        Path to the downloaded file, or None if download fails\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create SFTP connection\n",
    "        transport = paramiko.Transport((SFTP_HOST, 22))\n",
    "        transport.connect(username=SFTP_USER, password=SFTP_PASSWORD)\n",
    "        sftp = paramiko.SFTPClient.from_transport(transport)\n",
    "        \n",
    "        print(f\"Connected to SFTP server: {SFTP_HOST}\")\n",
    "        \n",
    "        # Change to remote directory\n",
    "        sftp.chdir(SFTP_REMOTE_PATH)\n",
    "        print(f\"Changed to directory: {SFTP_REMOTE_PATH}\")\n",
    "        \n",
    "        # List all files in the directory\n",
    "        files = sftp.listdir()\n",
    "        print(f\"Found {len(files)} files in directory\")\n",
    "        \n",
    "        # Filter for standalone content files and parse dates\n",
    "        content_files = []\n",
    "        for filename in files:\n",
    "            parsed = parse_standalone_content_filename(filename)\n",
    "            if parsed:\n",
    "                content_files.append((filename, parsed[3]))  # (filename, datetime_obj)\n",
    "        \n",
    "        if not content_files:\n",
    "            print(\"No valid StandAloneContent files found\")\n",
    "            sftp.close()\n",
    "            transport.close()\n",
    "            return None\n",
    "        \n",
    "        # Sort by date (most recent first)\n",
    "        content_files.sort(key=lambda x: x[1], reverse=True)\n",
    "        most_recent_file = content_files[0][0]\n",
    "        most_recent_date = content_files[0][1]\n",
    "        \n",
    "        print(f\"Most recent file: {most_recent_file} (date: {most_recent_date.strftime('%Y-%m-%d')})\")\n",
    "        \n",
    "        # Download the file\n",
    "        local_path = os.path.join(SFTP_LOCAL_DIR, most_recent_file)\n",
    "        sftp.get(most_recent_file, local_path)\n",
    "        print(f\"Downloaded to: {local_path}\")\n",
    "        \n",
    "        # Close connections\n",
    "        sftp.close()\n",
    "        transport.close()\n",
    "        \n",
    "        return local_path\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading standalone content: {e}\")\n",
    "        print(f\"  SFTP Host: {SFTP_HOST}\")\n",
    "        print(f\"  SFTP Path: {SFTP_REMOTE_PATH}\")\n",
    "        print(f\"  SFTP User: {SFTP_USER}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "PREPROCESSING - Download Files from SFTP\n",
      "================================================================================\n",
      "\n",
      "Downloading Course Catalog...\n",
      "--------------------------------------------------------------------------------\n",
      "Connected to SFTP server: sftp.sephora.com\n",
      "Changed to directory: /inbound/BTC/retailData/prod/vendor/mySephoraLearning-archive\n"
     ]
    }
   ],
   "source": [
    "# Execute: Download Course Catalog and Standalone Content from SFTP\n",
    "print(\"=\" * 80)\n",
    "print(\"PREPROCESSING - Download Files from SFTP\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "# Download Course Catalog\n",
    "print(\"Downloading Course Catalog...\")\n",
    "print(\"-\" * 80)\n",
    "course_catalog_path = download_most_recent_course_catalog()\n",
    "\n",
    "if course_catalog_path:\n",
    "    print()\n",
    "    print(f\"✓ Course catalog downloaded successfully\")\n",
    "    print(f\"  File: {course_catalog_path}\")\n",
    "    \n",
    "    # Optionally load and preview the file\n",
    "    try:\n",
    "        catalog_df = pd.read_csv(course_catalog_path)\n",
    "        print(f\"  Rows: {len(catalog_df)}\")\n",
    "        print(f\"  Columns: {list(catalog_df.columns)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  Note: Could not preview file: {e}\")\n",
    "else:\n",
    "    print()\n",
    "    print(\"✗ Failed to download course catalog\")\n",
    "    print(\"  Please check:\")\n",
    "    print(\"    1. .env file contains valid SFTP_PASSWORD\")\n",
    "    print(\"    2. SFTP server is accessible\")\n",
    "    print(\"    3. Remote path exists and contains CourseCatalog files\")\n",
    "\n",
    "print()\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Download Standalone Content\n",
    "print(\"Downloading Standalone Content...\")\n",
    "print(\"-\" * 80)\n",
    "standalone_content_path = download_most_recent_standalone_content()\n",
    "\n",
    "if standalone_content_path:\n",
    "    print()\n",
    "    print(f\"✓ Standalone content downloaded successfully\")\n",
    "    print(f\"  File: {standalone_content_path}\")\n",
    "    \n",
    "    # Optionally load and preview the file\n",
    "    try:\n",
    "        content_df = pd.read_csv(standalone_content_path)\n",
    "        print(f\"  Rows: {len(content_df)}\")\n",
    "        print(f\"  Columns: {list(content_df.columns)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  Note: Could not preview file: {e}\")\n",
    "else:\n",
    "    print()\n",
    "    print(\"✗ Failed to download standalone content\")\n",
    "    print(\"  Please check:\")\n",
    "    print(\"    1. .env file contains valid SFTP_PASSWORD\")\n",
    "    print(\"    2. SFTP server is accessible\")\n",
    "    print(\"    3. Remote path exists and contains StandAloneContent files\")\n",
    "\n",
    "print()\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading employees from input/employees.csv...\n",
      "Filtered out 17 comment row(s)\n",
      "Loaded 12 employees\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load employees (used by both Manager and Employee Training sections)\n",
    "print(f\"Loading employees from {EMPLOYEES_FILE}...\")\n",
    "employees_df = pd.read_csv(EMPLOYEES_FILE)\n",
    "\n",
    "# Filter out comment rows (rows where employee_id starts with '#')\n",
    "initial_count = len(employees_df)\n",
    "employees_df['employee_id'] = employees_df['employee_id'].astype(str)\n",
    "employees_df = employees_df[~employees_df['employee_id'].str.startswith('#')].copy()\n",
    "\n",
    "# Convert employee_id back to int after filtering comments\n",
    "employees_df['employee_id'] = employees_df['employee_id'].astype(int)\n",
    "\n",
    "filtered_count = initial_count - len(employees_df)\n",
    "\n",
    "if filtered_count > 0:\n",
    "    print(f\"Filtered out {filtered_count} comment row(s)\")\n",
    "\n",
    "print(f\"Loaded {len(employees_df)} employees\")\n",
    "print()\n",
    "\n",
    "# Helper function for formatting content IDs (used by both sections)\n",
    "def format_content_id(content_id: int) -> str:\n",
    "    \"\"\"\n",
    "    Format content ID with commas for human readability.\n",
    "    Example: 1915085 -> \"1,915,085\"\n",
    "    \n",
    "    Args:\n",
    "        content_id: The numeric content ID\n",
    "    \n",
    "    Returns:\n",
    "        Formatted string with commas\n",
    "    \"\"\"\n",
    "    return f\"{content_id:,}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manager - Assign Training to Employees\n",
    "\n",
    "This section implements the manager functionality:\n",
    "1. Loads the standalone content file from preprocessing\n",
    "2. Filters for content where Daily_Dose_BA is TRUE\n",
    "3. Sorts by CreateDate (most recent first)\n",
    "4. Selects up to 3 contents to assign\n",
    "5. Assigns the selected contents to all employees\n",
    "6. Generates a NonCompletedAssignments CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import pytz\n\n# Date/time helper functions - all use PT timezone defined in Cell 2\n\ndef get_monday_of_current_week() -> datetime:\n    \"\"\"\n    Get Monday of the current week at 00:01 PT.\n    \n    Returns:\n        datetime object for Monday of current week at 00:01 PT\n    \"\"\"\n    now = datetime.now(PT)\n    # Monday is 0, Sunday is 6\n    days_since_monday = now.weekday()\n    \n    # Go back to Monday of current week\n    monday = now - timedelta(days=days_since_monday)\n    \n    # Set time to 00:01 PT\n    return monday.replace(hour=0, minute=1, second=0, microsecond=0)\n\ndef get_next_future_monday() -> datetime:\n    \"\"\"\n    Get the next future Monday at 23:59 PT.\n    \n    Returns:\n        datetime object for the next future Monday at 23:59 PT\n    \"\"\"\n    now = datetime.now(PT)\n    # Monday is 0, Sunday is 6\n    current_weekday = now.weekday()\n    \n    # Calculate days until next Monday\n    if current_weekday == 0:\n        # Today is Monday, next Monday is 7 days away\n        days_until_monday = 7\n    else:\n        # Days until next Monday\n        days_until_monday = (7 - current_weekday)\n    \n    next_monday = now + timedelta(days=days_until_monday)\n    \n    # Set time to 23:59 PT\n    return next_monday.replace(hour=23, minute=59, second=0, microsecond=0)\n\ndef generate_request_id() -> str:\n    \"\"\"\n    Generate RequestId in format: MMDDYY:Random3Digits\n    Example: 010726:347\n    Uses PT timezone for date components.\n    \n    Returns:\n        RequestId string\n    \"\"\"\n    now = datetime.now(PT)\n    month = now.strftime(\"%m\")\n    day = now.strftime(\"%d\")\n    year = now.strftime(\"%y\")\n    random_digits = random.randint(100, 999)\n    \n    return f\"{month}{day}{year}:{random_digits}\"\n\ndef generate_non_completed_assignments_filename() -> str:\n    \"\"\"\n    Generate NonCompletedAssignments filename with timestamp and random suffix.\n    Format: Non_Completed_Assignments_V2_YYYY_M_DD_1_RAND.csv\n    Uses PT timezone for date components.\n    \n    Returns:\n        Generated filename\n    \"\"\"\n    now = datetime.now(PT)\n    year = now.strftime(\"%Y\")\n    month = now.strftime(\"%-m\")  # No leading zero\n    day = now.strftime(\"%-d\")    # No leading zero\n    \n    # Generate 6-character random alphanumeric suffix\n    random_suffix = ''.join(random.choices(string.ascii_lowercase + string.digits, k=6))\n    \n    return f\"Non_Completed_Assignments_V2_{year}_{month}_{day}_1_{random_suffix}.csv\""
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manager - Select training content to assign to employees\n",
    "print(\"=\" * 80)\n",
    "print(\"MANAGER - Assigning Training to Employees\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "# Load the standalone content file that was downloaded earlier\n",
    "if standalone_content_path and os.path.exists(standalone_content_path):\n",
    "    print(f\"Loading standalone content from: {standalone_content_path}\")\n",
    "    standalone_df = pd.read_csv(standalone_content_path)\n",
    "    print(f\"Loaded {len(standalone_df)} content items\")\n",
    "    print()\n",
    "    \n",
    "    # Filter for content where Daily_Dose_BA is TRUE\n",
    "    print(\"Filtering for Daily_Dose_BA = TRUE...\")\n",
    "    # Handle both string \"TRUE\" and boolean True\n",
    "    daily_dose_content = standalone_df[\n",
    "        (standalone_df['Daily_Dose_BA'] == 'TRUE') | \n",
    "        (standalone_df['Daily_Dose_BA'] == True)\n",
    "    ].copy()\n",
    "    \n",
    "    print(f\"Found {len(daily_dose_content)} items with Daily_Dose_BA = TRUE\")\n",
    "    print()\n",
    "    \n",
    "    if len(daily_dose_content) > 0:\n",
    "        # Convert CreateDate to datetime for sorting\n",
    "        daily_dose_content['CreateDate_dt'] = pd.to_datetime(daily_dose_content['CreateDate'])\n",
    "        \n",
    "        # Sort by CreateDate (most recent first)\n",
    "        daily_dose_content = daily_dose_content.sort_values('CreateDate_dt', ascending=False)\n",
    "        \n",
    "        # Select up to 3 most recent contents\n",
    "        contents_to_assign = daily_dose_content.head(3)\n",
    "        \n",
    "        print(f\"Selected {len(contents_to_assign)} content(s) to assign:\")\n",
    "        for idx, content in contents_to_assign.iterrows():\n",
    "            content_id = content['ContentId']\n",
    "            content_name = content['ContentName']\n",
    "            create_date = content['CreateDate']\n",
    "            print(f\"  {format_content_id(int(content_id.replace(',', '')))} - {content_name} (Created: {create_date})\")\n",
    "        print()\n",
    "        \n",
    "        # Create assignments for all employees\n",
    "        print(f\"Creating assignments for {len(employees_df)} employees...\")\n",
    "        \n",
    "        all_assignments = []\n",
    "        \n",
    "        # Calculate dates for assignments in PT\n",
    "        created_date = (datetime.now(PT) - timedelta(minutes=5)).isoformat()\n",
    "        start_date = get_monday_of_current_week().isoformat()\n",
    "        due_date = get_next_future_monday().isoformat()\n",
    "        \n",
    "        for _, employee in employees_df.iterrows():\n",
    "            employee_id = employee['employee_id']\n",
    "            \n",
    "            # Assign each selected content to this employee\n",
    "            for _, content in contents_to_assign.iterrows():\n",
    "                content_id = content['ContentId']\n",
    "                \n",
    "                assignment = {\n",
    "                    \"UserID\": employee_id,\n",
    "                    \"CreateDate_text\": created_date,\n",
    "                    \"RequestId\": generate_request_id(),\n",
    "                    \"TrainingElementId\": content_id,\n",
    "                    \"Start_Date_text\": start_date,\n",
    "                    \"DueDate_text\": due_date,\n",
    "                    \"ContentType\": \"Media\"\n",
    "                }\n",
    "                \n",
    "                all_assignments.append(assignment)\n",
    "        \n",
    "        print(f\"Created {len(all_assignments)} total assignments\")\n",
    "        print()\n",
    "        \n",
    "        # Generate output file\n",
    "        if all_assignments:\n",
    "            assignments_filename = generate_non_completed_assignments_filename()\n",
    "            assignments_path = f\"{OUTPUT_DIR}/{assignments_filename}\"\n",
    "            \n",
    "            # Create DataFrame\n",
    "            assignments_df = pd.DataFrame(all_assignments)\n",
    "            \n",
    "            # Write to CSV with proper quoting\n",
    "            assignments_df.to_csv(assignments_path, index=False, quoting=1)  # quoting=1 means QUOTE_ALL\n",
    "            \n",
    "            print(f\"Generated NonCompletedAssignments file: {assignments_filename}\")\n",
    "            print(f\"Total assignments: {len(all_assignments)}\")\n",
    "            print()\n",
    "            \n",
    "            # Print summary\n",
    "            print(\"Assignment Summary:\")\n",
    "            print(f\"  Employees: {len(employees_df)}\")\n",
    "            print(f\"  Contents assigned: {len(contents_to_assign)}\")\n",
    "            print(f\"  Total assignments: {len(all_assignments)}\")\n",
    "            print(f\"  Start Date (Monday of current week): {start_date}\")\n",
    "            print(f\"  Due Date (next future Monday): {due_date}\")\n",
    "        else:\n",
    "            print(\"No assignments created.\")\n",
    "    else:\n",
    "        print(\"No content found with Daily_Dose_BA = TRUE\")\n",
    "        print(\"No assignments created.\")\n",
    "else:\n",
    "    print(\"Standalone content file not found.\")\n",
    "    print(\"Please run the preprocessing section first.\")\n",
    "\n",
    "print()\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Employee Training Simulation\n",
    "\n",
    "This section simulates employees completing training based on manager assignments and AI recommendations:\n",
    "\n",
    "## Workflow:\n",
    "1. **Get Recommendations** (next cell): Calls ML Training Recommender API for each employee\n",
    "2. **Get Manager Assignments**: Loads assignments from NonCompletedAssignments file created by manager\n",
    "3. **Combine Training**: Merges manager assignments with AI recommendations\n",
    "4. **Helper Functions** (following cell): Generates training timestamps\n",
    "5. **Process Employee**: Determines completions based on employee type:\n",
    "   - Type A: Completes all training (manager + AI)\n",
    "   - Type B: Completes one training (from combined list)\n",
    "   - Type F: Completes no training\n",
    "6. **Filename Generator**: Creates unique output filename with timestamp\n",
    "7. **Main Loop**: Processes all employees and collects completion records\n",
    "8. **Generate Output**: Writes ContentUserCompletion CSV file\n",
    "9. **Print Summary**: Displays completion summary with source (manager or AI) for each employee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_recommendations(employee_id: int) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Call the training recommender API for a given employee.\n",
    "    \n",
    "    Args:\n",
    "        employee_id: The employee's ID (ba_id)\n",
    "    \n",
    "    Returns:\n",
    "        List of recommended training courses\n",
    "    \"\"\"\n",
    "    url = f\"{API_BASE_URL}{API_ENDPOINT}\"\n",
    "    payload = {\"data\": {\"ba_id\": employee_id}}\n",
    "    \n",
    "    try:\n",
    "        # Disable SSL certificate verification for internal APIs\n",
    "        response = requests.post(url, json=payload, timeout=30, verify=False)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        \n",
    "        # Response structure: {\"response\": {\"ml_recommendations\": [...], \"coaching_note\": {...}}, \"timing\": {...}, \"apiContext\": {...}}\n",
    "        if isinstance(data, dict):\n",
    "            response_data = data.get(\"response\", {})\n",
    "            if isinstance(response_data, dict):\n",
    "                # Get ml_recommendations from nested response\n",
    "                recommendations = response_data.get(\"ml_recommendations\", [])\n",
    "            else:\n",
    "                # Response is directly a list\n",
    "                recommendations = response_data if isinstance(response_data, list) else []\n",
    "        else:\n",
    "            print(f\"  Unexpected response type: {type(data)}\")\n",
    "            return []\n",
    "        \n",
    "        # Print selected fields from API response\n",
    "        if isinstance(recommendations, list) and recommendations:\n",
    "            print(f\"  API Response for employee {employee_id}:\")\n",
    "            for rec in recommendations:\n",
    "                ba_id = rec.get(\"ba_id\", \"N/A\")\n",
    "                content_id = rec.get(\"recommended_content_id\", \"N/A\")\n",
    "                recommended_content = rec.get(\"recommended_content\", \"N/A\")\n",
    "                print(f\"  {ba_id} | {content_id} | {recommended_content}\")\n",
    "            print()\n",
    "        \n",
    "        # Ensure we have a list\n",
    "        if isinstance(recommendations, list):\n",
    "            return recommendations\n",
    "        else:\n",
    "            print(f\"  Recommendations is not a list: {type(recommendations)}\")\n",
    "            return []\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"  Error fetching recommendations for employee {employee_id}: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def generate_training_times(num_courses: int) -> List[tuple]:\n    \"\"\"\n    Generate start and completion times for training courses in PT timezone.\n    Start time: Current day at 00:05 PT\n    Completion time: Current day at 00:09 PT\n    \n    All timestamps are returned in ISO-8601 format with PT timezone offset\n    (e.g., 2026-01-13T00:05:00-08:00), NOT in UTC.\n    \n    Args:\n        num_courses: Number of courses to generate times for\n    \n    Returns:\n        List of (start_time, end_time) tuples in ISO-8601 format with PT timezone\n    \"\"\"\n    times = []\n    now = datetime.now(PT)  # Use PT timezone\n    \n    # Set to current day at 00:05 PT for start time\n    start_time = now.replace(hour=0, minute=5, second=0, microsecond=0)\n    \n    # Set to current day at 00:09 PT for completion time\n    end_time = now.replace(hour=0, minute=9, second=0, microsecond=0)\n    \n    for _ in range(num_courses):\n        # .isoformat() preserves PT timezone in output\n        times.append((\n            start_time.isoformat(),\n            end_time.isoformat()\n        ))\n    \n    return times"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def process_employee(employee_id: int, employee_type: str, manager_assignments_path: str, standalone_df: pd.DataFrame, ai_recommendations: List[Dict] = None) -> List[Dict]:\n    \"\"\"\n    Process a single employee: get AI recommendations and manager assignments, then simulate completions.\n\n    Args:\n        employee_id: The employee's ID\n        employee_type: The employee's type (a, b, or f)\n        manager_assignments_path: Path to the NonCompletedAssignments CSV file\n        standalone_df: DataFrame containing standalone content for lookups\n        ai_recommendations: Optional pre-fetched AI recommendations (to avoid duplicate API calls)\n\n    Returns:\n        List of completed training records with PT timezone timestamps\n    \"\"\"\n    employee_type = employee_type.lower().strip()\n\n    # Get AI recommendations (use provided ones or fetch new)\n    if ai_recommendations is None:\n        ai_recommendations = get_training_recommendations(employee_id)\n\n    # Get manager assignments\n    manager_assignments = []\n    if os.path.exists(manager_assignments_path):\n        assignments_df = pd.read_csv(manager_assignments_path)\n        \n        # Convert UserID to int to match employee_id type\n        # (CSV with QUOTE_ALL reads as string, but employee_id is int)\n        assignments_df['UserID'] = assignments_df['UserID'].astype(int)\n        \n        # Filter for this employee\n        employee_assignments = assignments_df[assignments_df['UserID'] == employee_id]\n\n        for _, assignment in employee_assignments.iterrows():\n            # Get the TrainingElementId and look up the content name\n            content_id = assignment['TrainingElementId']\n\n            # Remove commas from content_id if present (it might be formatted)\n            if isinstance(content_id, str):\n                content_id_numeric = int(content_id.replace(',', ''))\n            else:\n                content_id_numeric = int(content_id)\n\n            # Look up content name in standalone_df\n            # Handle both numeric and string ContentId in standalone_df\n            content_row = standalone_df[\n                (standalone_df['ContentId'] == content_id) |\n                (standalone_df['ContentId'] == str(content_id_numeric))\n            ]\n            if not content_row.empty:\n                content_name = content_row.iloc[0]['ContentName']\n            else:\n                content_name = \"Unknown Manager Assignment\"\n\n            manager_assignments.append({\n                \"recommended_content_id\": content_id_numeric,\n                \"recommended_content\": content_name,\n                \"source\": \"manager\"\n            })\n\n    # Tag AI recommendations with source\n    for rec in ai_recommendations:\n        rec[\"source\"] = \"ai\"\n\n    # Combine manager assignments and AI recommendations\n    all_training = manager_assignments + ai_recommendations\n\n    if not all_training:\n        print(f\"  No training available for employee {employee_id}\")\n        return []\n\n    print(f\"  Total training available: {len(all_training)} ({len(manager_assignments)} manager + {len(ai_recommendations)} AI)\")\n\n    # Determine how many courses to complete based on employee type\n    if employee_type == 'a':\n        # Type A: complete all training (manager + AI)\n        courses_to_complete = all_training\n    elif employee_type == 'b':\n        # Type B: complete one training (from combined list)\n        courses_to_complete = all_training[:1]\n    else:\n        # Type F: complete no training\n        courses_to_complete = []\n\n    # Generate completion records with PT timezone timestamps\n    completions = []\n    times = generate_training_times(len(courses_to_complete))\n\n    for i, course in enumerate(courses_to_complete):\n        try:\n            # Validate course is a dict\n            if not isinstance(course, dict):\n                print(f\"  WARNING: Course is not a dict, it's {type(course)}: {course}\")\n                continue\n\n            start_time, end_time = times[i]\n            source = course.get(\"source\", \"unknown\")\n            completions.append({\n                \"UserId\": employee_id,\n                \"ContentId\": format_content_id(course[\"recommended_content_id\"]),\n                \"DateStarted\": start_time,  # ISO-8601 with PT timezone\n                \"DateCompleted\": end_time,  # ISO-8601 with PT timezone\n                \"CourseName\": course.get(\"recommended_content\", \"Unknown\"),\n                \"Source\": source\n            })\n        except KeyError as e:\n            print(f\"  WARNING: Missing key {e} in course data: {course}\")\n            continue\n        except Exception as e:\n            print(f\"  WARNING: Error processing course: {e}\")\n            continue\n\n    return completions\n\ndef generate_output_filename() -> str:\n    \"\"\"\n    Generate output filename with PT timestamp and random suffix.\n    Format: ContentUserCompletion_V2_YYYY_MM_DD_1_RAND.csv\n    Uses PT timezone for date components for consistency.\n    \n    Returns:\n        Generated filename\n    \"\"\"\n    now = datetime.now(PT)  # Use PT timezone for consistency\n    year = now.strftime(\"%Y\")\n    month = now.strftime(\"%m\")\n    day = now.strftime(\"%d\")\n    \n    # Generate 6-character random alphanumeric suffix\n    random_suffix = ''.join(random.choices(string.ascii_lowercase + string.digits, k=6))\n    \n    return f\"ContentUserCompletion_V2_{year}_{month}_{day}_1_{random_suffix}.csv\""
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "EMPLOYEE TRAINING SIMULATION\n",
      "================================================================================\n",
      "\n",
      "Processing Employee 63419 (Type A)...\n",
      "  API Response for employee 63419:\n",
      "  63419 | 657908 | Sell. How to Reassure Your Client\n",
      "  63419 | 594096 | Sell. When Clients Say No\n",
      "\n",
      "  Total training available: 5 (3 manager + 2 AI)\n",
      "  Completed 5 training(s)\n",
      "\n",
      "Processing Employee 63492 (Type B)...\n",
      "  Total training available: 3 (3 manager + 0 AI)\n",
      "  Completed 1 training(s)\n",
      "\n",
      "Processing Employee 75412 (Type B)...\n",
      "  Total training available: 3 (3 manager + 0 AI)\n",
      "  Completed 1 training(s)\n",
      "\n",
      "Processing Employee 85038 (Type B)...\n",
      "  API Response for employee 85038:\n",
      "  85038 | 913731 | Sell. How to Multiworld Sell\n",
      "  85038 | 1717886 | Get - Client Cues\n",
      "\n",
      "  Total training available: 5 (3 manager + 2 AI)\n",
      "  Completed 1 training(s)\n",
      "\n",
      "Processing Employee 86994 (Type F)...\n",
      "  API Response for employee 86994:\n",
      "  86994 | 892298 | Fragrance - Get. Give. Teach. Sell.\n",
      "  86994 | 574327 | Servicing Multiple Clients\n",
      "\n",
      "  Total training available: 5 (3 manager + 2 AI)\n",
      "  No training completed\n",
      "\n",
      "Processing Employee 88563 (Type F)...\n",
      "  API Response for employee 88563:\n",
      "  88563 | 892298 | Fragrance - Get. Give. Teach. Sell.\n",
      "  88563 | 1717885 | Give - Active Listening\n",
      "\n",
      "  Total training available: 5 (3 manager + 2 AI)\n",
      "  No training completed\n",
      "\n",
      "Processing Employee 104829 (Type A)...\n",
      "  API Response for employee 104829:\n",
      "  104829 | 574327 | Servicing Multiple Clients\n",
      "  104829 | 721089 | Sell. How to Multiworld Sell\n",
      "\n",
      "  Total training available: 5 (3 manager + 2 AI)\n",
      "  Completed 5 training(s)\n",
      "\n",
      "Processing Employee 109828 (Type A)...\n",
      "  API Response for employee 109828:\n",
      "  109828 | 1549460 | Sell.\n",
      "  109828 | 1032736 | Sell. Driving Multiworld Sales\n",
      "\n",
      "  Total training available: 5 (3 manager + 2 AI)\n",
      "  Completed 5 training(s)\n",
      "\n",
      "Processing Employee 151557 (Type A)...\n",
      "  API Response for employee 151557:\n",
      "  151557 | 594097 | Sell. Three Ways to Sell\n",
      "  151557 | 574327 | Servicing Multiple Clients\n",
      "\n",
      "  Total training available: 5 (3 manager + 2 AI)\n",
      "  Completed 5 training(s)\n",
      "\n",
      "Processing Employee 155810 (Type A)...\n",
      "  API Response for employee 155810:\n",
      "  155810 | 594096 | Sell. When Clients Say No\n",
      "  155810 | 657907 | Sell. How to Add on\n",
      "\n",
      "  Total training available: 5 (3 manager + 2 AI)\n",
      "  Completed 5 training(s)\n",
      "\n",
      "Processing Employee 173789 (Type A)...\n",
      "  API Response for employee 173789:\n",
      "  173789 | 863648 | Sell. How to Add on\n",
      "  173789 | 863652 | Sell. How to Reassure Your Client\n",
      "\n",
      "  Total training available: 5 (3 manager + 2 AI)\n",
      "  Completed 5 training(s)\n",
      "\n",
      "Processing Employee 175342 (Type A)...\n",
      "  API Response for employee 175342:\n",
      "  175342 | 892298 | Fragrance - Get. Give. Teach. Sell.\n",
      "  175342 | 1737126 | Get the Client\n",
      "\n",
      "  Total training available: 5 (3 manager + 2 AI)\n",
      "  Completed 5 training(s)\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Main execution - Process employees and simulate training completions\n",
    "print(\"=\" * 80)\n",
    "print(\"EMPLOYEE TRAINING SIMULATION\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "# Check if manager assignments were created\n",
    "if 'assignments_path' not in locals() or not os.path.exists(assignments_path):\n",
    "    print(\"WARNING: Manager assignments file not found. Employees will only complete AI recommendations.\")\n",
    "    print()\n",
    "    assignments_path = \"\"\n",
    "\n",
    "# Process each employee\n",
    "all_completions = []\n",
    "employee_summaries = []\n",
    "employee_ml_recommendations = []  # Store ML recommendations for summary\n",
    "\n",
    "for _, employee in employees_df.iterrows():\n",
    "    employee_id = employee['employee_id']\n",
    "    employee_type = employee['employee_edu_type']\n",
    "    \n",
    "    print(f\"Processing Employee {employee_id} (Type {employee_type.upper()})...\")\n",
    "    \n",
    "    # Get AI recommendations\n",
    "    ai_recommendations = get_training_recommendations(employee_id)\n",
    "    \n",
    "    # Store ML recommendations for this employee\n",
    "    if ai_recommendations:\n",
    "        ml_recs = []\n",
    "        for rec in ai_recommendations:\n",
    "            ml_recs.append({\n",
    "                \"content_id\": rec.get(\"recommended_content_id\"),\n",
    "                \"content_name\": rec.get(\"recommended_content\", \"Unknown\")\n",
    "            })\n",
    "        employee_ml_recommendations.append((employee_id, ml_recs))\n",
    "    \n",
    "    # Process employee with pre-fetched AI recommendations\n",
    "    completions = process_employee(employee_id, employee_type, assignments_path, standalone_df, ai_recommendations)\n",
    "    \n",
    "    if completions:\n",
    "        all_completions.extend(completions)\n",
    "        # Store ContentId, CourseName, and Source for summary\n",
    "        course_details = [(c['ContentId'], c['CourseName'], c['Source']) for c in completions]\n",
    "        employee_summaries.append((employee_id, course_details))\n",
    "        print(f\"  Completed {len(completions)} training(s)\")\n",
    "    else:\n",
    "        print(f\"  No training completed\")\n",
    "    print()\n",
    "\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate output file\n",
    "if all_completions:\n",
    "    output_filename = generate_output_filename()\n",
    "    output_path = f\"{OUTPUT_DIR}/{output_filename}\"\n",
    "    \n",
    "    # Create DataFrame with only the required columns for CSV\n",
    "    output_df = pd.DataFrame(all_completions)\n",
    "    output_df = output_df[['UserId', 'ContentId', 'DateStarted', 'DateCompleted']]\n",
    "    \n",
    "    # Write to CSV with proper quoting\n",
    "    output_df.to_csv(output_path, index=False, quoting=1)  # quoting=1 means QUOTE_ALL\n",
    "    \n",
    "    print(f\"Generated output file: {output_filename}\")\n",
    "    print(f\"Total completions: {len(all_completions)}\")\n",
    "    print()\n",
    "else:\n",
    "    print(\"No training completions to write.\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "MANAGER-ASSIGNMENTS GIVEN\n",
      "================================================================================\n",
      "\n",
      "Training Assignments:\n",
      "  Content ID: 1,995,576       | Course Name: December Training Product\n",
      "  Content ID: 2,021,630       | Course Name: What's Hot For January\n",
      "  Content ID: 2,024,318       | Course Name: Skincare Consultations with Teens and Tweens\n",
      "Employees: 63419, 63492, 75412, 85038, 86994, 88563, 104829, 109828, 151557, 155810, 173789, 175342\n",
      "\n",
      "================================================================================\n",
      "ML-RECOMMENDATIONS GIVEN\n",
      "================================================================================\n",
      "\n",
      "ML Recommendations:\n",
      "  Content ID: 594096          | Course Name: Sell. When Clients Say No\n",
      "  Content ID: 657908          | Course Name: Sell. How to Reassure Your Client\n",
      "Employees: 63419\n",
      "\n",
      "ML Recommendations:\n",
      "  Content ID: 1717886         | Course Name: Get - Client Cues\n",
      "  Content ID: 913731          | Course Name: Sell. How to Multiworld Sell\n",
      "Employees: 85038\n",
      "\n",
      "ML Recommendations:\n",
      "  Content ID: 574327          | Course Name: Servicing Multiple Clients\n",
      "  Content ID: 892298          | Course Name: Fragrance - Get. Give. Teach. Sell.\n",
      "Employees: 86994\n",
      "\n",
      "ML Recommendations:\n",
      "  Content ID: 1717885         | Course Name: Give - Active Listening\n",
      "  Content ID: 892298          | Course Name: Fragrance - Get. Give. Teach. Sell.\n",
      "Employees: 88563\n",
      "\n",
      "ML Recommendations:\n",
      "  Content ID: 574327          | Course Name: Servicing Multiple Clients\n",
      "  Content ID: 721089          | Course Name: Sell. How to Multiworld Sell\n",
      "Employees: 104829\n",
      "\n",
      "ML Recommendations:\n",
      "  Content ID: 1032736         | Course Name: Sell. Driving Multiworld Sales\n",
      "  Content ID: 1549460         | Course Name: Sell.\n",
      "Employees: 109828\n",
      "\n",
      "ML Recommendations:\n",
      "  Content ID: 574327          | Course Name: Servicing Multiple Clients\n",
      "  Content ID: 594097          | Course Name: Sell. Three Ways to Sell\n",
      "Employees: 151557\n",
      "\n",
      "ML Recommendations:\n",
      "  Content ID: 594096          | Course Name: Sell. When Clients Say No\n",
      "  Content ID: 657907          | Course Name: Sell. How to Add on\n",
      "Employees: 155810\n",
      "\n",
      "ML Recommendations:\n",
      "  Content ID: 863648          | Course Name: Sell. How to Add on\n",
      "  Content ID: 863652          | Course Name: Sell. How to Reassure Your Client\n",
      "Employees: 173789\n",
      "\n",
      "ML Recommendations:\n",
      "  Content ID: 1737126         | Course Name: Get the Client\n",
      "  Content ID: 892298          | Course Name: Fragrance - Get. Give. Teach. Sell.\n",
      "Employees: 175342\n",
      "\n",
      "================================================================================\n",
      "MANAGER-ASSIGNED TRAINING COMPLETIONS\n",
      "================================================================================\n",
      "\n",
      "Employee ID     | Content ID      | Course Name\n",
      "--------------- | --------------- | --------------------------------------------------\n",
      "63419           | 2,024,318       | Skincare Consultations with Teens and Tweens\n",
      "63419           | 2,021,630       | What's Hot For January\n",
      "63419           | 1,995,576       | December Training Product\n",
      "63492           | 2,024,318       | Skincare Consultations with Teens and Tweens\n",
      "75412           | 2,024,318       | Skincare Consultations with Teens and Tweens\n",
      "85038           | 2,024,318       | Skincare Consultations with Teens and Tweens\n",
      "104829          | 2,024,318       | Skincare Consultations with Teens and Tweens\n",
      "104829          | 2,021,630       | What's Hot For January\n",
      "104829          | 1,995,576       | December Training Product\n",
      "109828          | 2,024,318       | Skincare Consultations with Teens and Tweens\n",
      "109828          | 2,021,630       | What's Hot For January\n",
      "109828          | 1,995,576       | December Training Product\n",
      "151557          | 2,024,318       | Skincare Consultations with Teens and Tweens\n",
      "151557          | 2,021,630       | What's Hot For January\n",
      "151557          | 1,995,576       | December Training Product\n",
      "155810          | 2,024,318       | Skincare Consultations with Teens and Tweens\n",
      "155810          | 2,021,630       | What's Hot For January\n",
      "155810          | 1,995,576       | December Training Product\n",
      "173789          | 2,024,318       | Skincare Consultations with Teens and Tweens\n",
      "173789          | 2,021,630       | What's Hot For January\n",
      "173789          | 1,995,576       | December Training Product\n",
      "175342          | 2,024,318       | Skincare Consultations with Teens and Tweens\n",
      "175342          | 2,021,630       | What's Hot For January\n",
      "175342          | 1,995,576       | December Training Product\n",
      "\n",
      "================================================================================\n",
      "ML-RECOMMENDED TRAINING COMPLETIONS\n",
      "================================================================================\n",
      "\n",
      "Employee ID     | Content ID      | Course Name\n",
      "--------------- | --------------- | --------------------------------------------------\n",
      "63419           | 657,908         | Sell. How to Reassure Your Client\n",
      "63419           | 594,096         | Sell. When Clients Say No\n",
      "104829          | 574,327         | Servicing Multiple Clients\n",
      "104829          | 721,089         | Sell. How to Multiworld Sell\n",
      "109828          | 1,549,460       | Sell.\n",
      "109828          | 1,032,736       | Sell. Driving Multiworld Sales\n",
      "151557          | 594,097         | Sell. Three Ways to Sell\n",
      "151557          | 574,327         | Servicing Multiple Clients\n",
      "155810          | 594,096         | Sell. When Clients Say No\n",
      "155810          | 657,907         | Sell. How to Add on\n",
      "173789          | 863,648         | Sell. How to Add on\n",
      "173789          | 863,652         | Sell. How to Reassure Your Client\n",
      "175342          | 892,298         | Fragrance - Get. Give. Teach. Sell.\n",
      "175342          | 1,737,126       | Get the Client\n",
      "\n",
      "================================================================================\n",
      "Simulation complete!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Print summary\n",
    "print(\"=\" * 80)\n",
    "print(\"MANAGER-ASSIGNMENTS GIVEN\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "# Display all assignments created by the manager, grouped by assignment set\n",
    "if 'assignments_path' in locals() and os.path.exists(assignments_path):\n",
    "    assignments_df = pd.read_csv(assignments_path)\n",
    "    \n",
    "    if len(assignments_df) > 0:\n",
    "        # Step 1: Group assignments by employee to get each employee's set of trainings\n",
    "        employee_assignments = {}\n",
    "        \n",
    "        for _, assignment in assignments_df.iterrows():\n",
    "            employee_id = assignment['UserID']\n",
    "            content_id = assignment['TrainingElementId']\n",
    "            \n",
    "            if employee_id not in employee_assignments:\n",
    "                employee_assignments[employee_id] = []\n",
    "            employee_assignments[employee_id].append(content_id)\n",
    "        \n",
    "        # Step 2: Group employees by their set of trainings (using frozenset for hashability)\n",
    "        assignment_groups = {}\n",
    "        \n",
    "        for employee_id, content_list in employee_assignments.items():\n",
    "            # Sort content list for consistent ordering and convert to tuple for hashability\n",
    "            content_set = tuple(sorted(content_list, key=str))\n",
    "            \n",
    "            if content_set not in assignment_groups:\n",
    "                assignment_groups[content_set] = []\n",
    "            assignment_groups[content_set].append(employee_id)\n",
    "        \n",
    "        # Step 3: Print each group of employees with their common assignment set\n",
    "        for content_set, employee_list in assignment_groups.items():\n",
    "            print(\"Training Assignments:\")\n",
    "            \n",
    "            # Print each training in the set\n",
    "            for content_id in content_set:\n",
    "                # Look up content name in standalone_df\n",
    "                if isinstance(content_id, str):\n",
    "                    content_id_numeric = int(content_id.replace(',', ''))\n",
    "                else:\n",
    "                    content_id_numeric = int(content_id)\n",
    "                \n",
    "                # Find the course name\n",
    "                content_row = standalone_df[\n",
    "                    (standalone_df['ContentId'] == content_id) |\n",
    "                    (standalone_df['ContentId'] == str(content_id_numeric))\n",
    "                ]\n",
    "                \n",
    "                if not content_row.empty:\n",
    "                    course_name = content_row.iloc[0]['ContentName']\n",
    "                else:\n",
    "                    course_name = \"Unknown\"\n",
    "                \n",
    "                print(f\"  Content ID: {content_id:<15} | Course Name: {course_name}\")\n",
    "            \n",
    "            # Print employees who received this assignment set (comma-separated)\n",
    "            employee_ids_str = \", \".join([str(emp_id) for emp_id in sorted(employee_list)])\n",
    "            print(f\"Employees: {employee_ids_str}\")\n",
    "            print()\n",
    "    else:\n",
    "        print(\"No assignments were created by the manager.\")\n",
    "else:\n",
    "    print(\"No manager assignments file found.\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ML-RECOMMENDATIONS GIVEN\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "# Display all ML recommendations given to employees, grouped by recommendation set\n",
    "if employee_ml_recommendations:\n",
    "    # Step 1: Group employees by their recommendation set\n",
    "    recommendation_groups = {}\n",
    "    \n",
    "    for employee_id, ml_recs in employee_ml_recommendations:\n",
    "        # Sort recommendation list for consistent ordering and convert to tuple for hashability\n",
    "        rec_set = tuple(sorted([(rec[\"content_id\"], rec[\"content_name\"]) for rec in ml_recs], key=lambda x: str(x[0])))\n",
    "        \n",
    "        if rec_set not in recommendation_groups:\n",
    "            recommendation_groups[rec_set] = []\n",
    "        recommendation_groups[rec_set].append(employee_id)\n",
    "    \n",
    "    # Step 2: Print each group of employees with their common recommendation set\n",
    "    for rec_set, employee_list in recommendation_groups.items():\n",
    "        print(\"ML Recommendations:\")\n",
    "        \n",
    "        # Print each recommendation in the set\n",
    "        for content_id, content_name in rec_set:\n",
    "            print(f\"  Content ID: {content_id:<15} | Course Name: {content_name}\")\n",
    "        \n",
    "        # Print employees who received this recommendation set (comma-separated)\n",
    "        employee_ids_str = \", \".join([str(emp_id) for emp_id in sorted(employee_list)])\n",
    "        print(f\"Employees: {employee_ids_str}\")\n",
    "        print()\n",
    "else:\n",
    "    print(\"No ML recommendations were given to any employee.\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"MANAGER-ASSIGNED TRAINING COMPLETIONS\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "# Track if any manager assignments were completed\n",
    "manager_completions_found = False\n",
    "\n",
    "# Collect all manager completions for table display\n",
    "manager_completion_rows = []\n",
    "\n",
    "for employee_id, course_details in employee_summaries:\n",
    "    # Filter for manager-assigned training only\n",
    "    manager_courses = [(content_id, course_name) for content_id, course_name, source in course_details if source == \"manager\"]\n",
    "    \n",
    "    if manager_courses:\n",
    "        manager_completions_found = True\n",
    "        for content_id, course_name in manager_courses:\n",
    "            manager_completion_rows.append((employee_id, content_id, course_name))\n",
    "\n",
    "if manager_completions_found:\n",
    "    # Print header\n",
    "    print(f\"{'Employee ID':<15} | {'Content ID':<15} | {'Course Name'}\")\n",
    "    print(f\"{'-' * 15} | {'-' * 15} | {'-' * 50}\")\n",
    "    \n",
    "    # Print each completion on a separate row\n",
    "    for employee_id, content_id, course_name in manager_completion_rows:\n",
    "        print(f\"{employee_id:<15} | {content_id:<15} | {course_name}\")\n",
    "else:\n",
    "    print(\"No manager-assigned training was completed by any employee.\")\n",
    "\n",
    "print()\n",
    "print(\"=\" * 80)\n",
    "print(\"ML-RECOMMENDED TRAINING COMPLETIONS\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "# Track if any ML recommendations were completed\n",
    "ml_completions_found = False\n",
    "\n",
    "# Collect all ML completions for table display\n",
    "ml_completion_rows = []\n",
    "\n",
    "for employee_id, course_details in employee_summaries:\n",
    "    # Filter for ML-recommended training only\n",
    "    ml_courses = [(content_id, course_name) for content_id, course_name, source in course_details if source == \"ai\"]\n",
    "    \n",
    "    if ml_courses:\n",
    "        ml_completions_found = True\n",
    "        for content_id, course_name in ml_courses:\n",
    "            ml_completion_rows.append((employee_id, content_id, course_name))\n",
    "\n",
    "if ml_completions_found:\n",
    "    # Print header\n",
    "    print(f\"{'Employee ID':<15} | {'Content ID':<15} | {'Course Name'}\")\n",
    "    print(f\"{'-' * 15} | {'-' * 15} | {'-' * 50}\")\n",
    "    \n",
    "    # Print each completion on a separate row\n",
    "    for employee_id, content_id, course_name in ml_completion_rows:\n",
    "        print(f\"{employee_id:<15} | {content_id:<15} | {course_name}\")\n",
    "else:\n",
    "    print(\"No ML-recommended training was completed by any employee.\")\n",
    "\n",
    "print()\n",
    "print(\"=\" * 80)\n",
    "print(\"Simulation complete!\")\n",
    "print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}